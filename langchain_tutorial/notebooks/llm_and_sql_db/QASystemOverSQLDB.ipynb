{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNxS+uaJTz4mJ2wBwOiTS5O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dimitarpg13/langchain_tutorial/blob/main/langchain_tutorial/notebooks/llm_and_sql_db/QASystemOverSQLDB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question/Answering system over SQL data\n",
        "\n",
        "### Workflow\n",
        "\n",
        "1. Convert question to SQL query: Model converts user input to a SQL query.\n",
        "\n",
        "2. Execute SQL query: Execute the query.\n",
        "\n",
        "3. Answer the question: Model responds to user input using the query results.\n"
      ],
      "metadata": {
        "id": "RSl_zKfLwBa4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "u9RJAnXYvEEK"
      },
      "outputs": [],
      "source": [
        "%%capture --no-stderr\n",
        "%pip install --upgrade --quiet langchain-community langgraph"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "initialize appropriate env variables"
      ],
      "metadata": {
        "id": "5TutkqTb02pq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, getpass\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "def _set_env(var: str):\n",
        "  if not os.environ.get(var):\n",
        "    os.environ[var] = getpass.getpass(f\"{var}: \")\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "_set_env(\"LANGSMITH_API_KEY\")\n",
        "\n",
        "os.environ[\"LANGSMITH_TRACING\"] = \"true\""
      ],
      "metadata": {
        "id": "abtj9rwK1aoZ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sample Data\n",
        "\n",
        "The below example will use a SQLite connection with the Chinook database, which is a sample database that represents a digital media store. Follow [these installation steps](https://database.guide/2-sample-databases-sqlite/) to create Chinook.db in the same directory as this notebook. You can also download and build the database via the following terminal command lines:\n",
        "\n",
        "```bash\n",
        "apt-get install sqlite3\n",
        "\n",
        "curl -s https://raw.githubusercontent.com/lerocha/chinook-database/master/ChinookDatabase/DataSources/Chinook_Sqlite.sql | sqlite3 Chinook.db\n",
        "```"
      ],
      "metadata": {
        "id": "IhgGv1BE1pVC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We interface with the freshly  created `Chinook.db` using the SQLAlchemy-driven `SQLDatabase` class:"
      ],
      "metadata": {
        "id": "TfiK0dNp8ZnT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.utilities import SQLDatabase\n",
        "\n",
        "db = SQLDatabase.from_uri(\"sqlite:///Chinook.db\")\n",
        "print(db.dialect)\n",
        "print(db.get_usable_table_names())\n",
        "db.run(\"SELECT * FROM Artist LIMIT 10;\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "rIAYHIo51-h8",
        "outputId": "1f3641e6-cc2f-4367-c209-b4a709ed23c0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sqlite\n",
            "['Album', 'Artist', 'Customer', 'Employee', 'Genre', 'Invoice', 'InvoiceLine', 'MediaType', 'Playlist', 'PlaylistTrack', 'Track']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"[(1, 'AC/DC'), (2, 'Accept'), (3, 'Aerosmith'), (4, 'Alanis Morissette'), (5, 'Alice In Chains'), (6, 'Ant√¥nio Carlos Jobim'), (7, 'Apocalyptica'), (8, 'Audioslave'), (9, 'BackBeat'), (10, 'Billy Cobham')]\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we define the application state of our chain:"
      ],
      "metadata": {
        "id": "Xt56e242BXzu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing_extensions import TypedDict\n",
        "\n",
        "\n",
        "class State(TypedDict):\n",
        "    question: str\n",
        "    query: str\n",
        "    result: str\n",
        "    answer: str"
      ],
      "metadata": {
        "id": "DLbMkyn_BbcH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convert question into a query\n",
        "\n",
        "To reliably obtain SQL queries (absent markdown formatting and explanations or clarifications), we will make use of [LangChain's structured output](https://python.langchain.com/docs/concepts/structured_outputs/) abstraction."
      ],
      "metadata": {
        "id": "gWByoQ_0CwrO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install --upgrade --quiet \"langchain[google-genai]\""
      ],
      "metadata": {
        "id": "EJb92E0mCv0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_set_env(\"GOOGLE_API_KEY\")\n",
        "\n",
        "from langchain.chat_models import init_chat_model\n",
        "\n",
        "llm = init_chat_model(\"gemini-2.0-flash\", model_provider=\"google_genai\")"
      ],
      "metadata": {
        "id": "FwmynMRbEhLl"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provide instructions to the model via a query prompt template:"
      ],
      "metadata": {
        "id": "vGY5QzmbPhsy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "system_message = \"\"\"\n",
        "Given an input question, create a syntactically correct {dialect} query to\n",
        "run to help find the answer. Unless the user specifies in his question a\n",
        "specific number of examples they wish to obtain, always limit your query to\n",
        "at most {top_k} results. You can order the results by a relevant column to\n",
        "return the most interesting examples in the database.\n",
        "\n",
        "Never query for all the columns from a specific table, only ask for a the\n",
        "few relevant columns given the question.\n",
        "\n",
        "Pay attention to use only the column names that you can see in the schema\n",
        "description. Be careful to not query for columns that do not exist. Also,\n",
        "pay attention to which column is in which table.\n",
        "\n",
        "Only use the following tables:\n",
        "{table_info}\n",
        "\"\"\"\n",
        "\n",
        "user_prompt = \"Question: {input}\"\n",
        "\n",
        "query_prompt_template = ChatPromptTemplate(\n",
        "    [(\"system\", system_message), (\"user\", user_prompt)]\n",
        ")\n",
        "\n",
        "for message in query_prompt_template.messages:\n",
        "    message.pretty_print()\n",
        "\n"
      ],
      "metadata": {
        "id": "oMaRaafwPppz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25dea022-34a9-4362-ae9f-2d6857a02f92"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m System Message \u001b[0m================================\n",
            "\n",
            "\n",
            "Given an input question, create a syntactically correct \u001b[33;1m\u001b[1;3m{dialect}\u001b[0m query to\n",
            "run to help find the answer. Unless the user specifies in his question a\n",
            "specific number of examples they wish to obtain, always limit your query to\n",
            "at most \u001b[33;1m\u001b[1;3m{top_k}\u001b[0m results. You can order the results by a relevant column to\n",
            "return the most interesting examples in the database.\n",
            "\n",
            "Never query for all the columns from a specific table, only ask for a the\n",
            "few relevant columns given the question.\n",
            "\n",
            "Pay attention to use only the column names that you can see in the schema\n",
            "description. Be careful to not query for columns that do not exist. Also,\n",
            "pay attention to which column is in which table.\n",
            "\n",
            "Only use the following tables:\n",
            "\u001b[33;1m\u001b[1;3m{table_info}\u001b[0m\n",
            "\n",
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Question: \u001b[33;1m\u001b[1;3m{input}\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The prompt includes several parameters we need to populate:\n",
        "\n",
        "* the sql dialect\n",
        "\n",
        "* the top_k value\n",
        "\n",
        "* table schema\n",
        "\n",
        "The method `write_query` defined below will populate these parameters by prompt a model to generate SQL query"
      ],
      "metadata": {
        "id": "IfpX8uBwcaz7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing_extensions import Annotated\n",
        "\n",
        "class QueryOutput(TypedDict):\n",
        "  \"\"\"Generated SQL query.\"\"\"\n",
        "\n",
        "  query: Annotated[str, ..., \"Synthactically valid SQL query.\"]\n",
        "\n",
        "def write_query(state: State):\n",
        "  \"\"\"Generate SQL query to fetch information.\"\"\"\n",
        "  prompt = query_prompt_template.invoke(\n",
        "      {\n",
        "\n",
        "      }\n",
        "  )"
      ],
      "metadata": {
        "id": "LIQEHMMrdBMC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}