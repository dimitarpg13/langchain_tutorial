{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "fb0ebaf1",
      "metadata": {
        "id": "fb0ebaf1"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dimitarpg13/langchain_tutorial/blob/main/langchain_tutorial/notebooks/message_processing/SerializableMessage.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c52ea2f9-03ff-4647-b782-46867ebed04e",
      "metadata": {
        "id": "c52ea2f9-03ff-4647-b782-46867ebed04e"
      },
      "source": [
        "# Working with Serializable Messages\n",
        "\n",
        "\n",
        "When working with LangChain message types in our state schema, there are important considerations for serialization. We should use `AnyMessage` instead of `BaseMessage` for proper serialization/deserialization of message objects.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "d5197aba-5d46-421b-ae3b-4e3034edcfda",
      "metadata": {
        "id": "d5197aba-5d46-421b-ae3b-4e3034edcfda"
      },
      "outputs": [],
      "source": [
        "%%capture --no-stderr\n",
        "%pip install --quiet -U langchain_core langgraph langchain_openai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, create a State object and a test node to test the message serialization:"
      ],
      "metadata": {
        "id": "qp3Cr5xZ5iIn"
      },
      "id": "qp3Cr5xZ5iIn"
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import StateGraph, START, END\n",
        "from pydantic import BaseModel\n",
        "from langchain_core.messages import HumanMessage, AIMessage, AnyMessage\n",
        "from typing import List\n",
        "\n",
        "class ChatState(BaseModel):\n",
        "    messages: List[AnyMessage]\n",
        "    context: str\n",
        "\n",
        "def add_message(state: ChatState):\n",
        "    return {\"messages\": state.messages + [AIMessage(content=\"Hello there!\")]}"
      ],
      "metadata": {
        "id": "BQFdSkeU4cNy"
      },
      "id": "BQFdSkeU4cNy",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create graph state , add a node and compile the new graph model:"
      ],
      "metadata": {
        "id": "NZvJoExM5q4B"
      },
      "id": "NZvJoExM5q4B"
    },
    {
      "cell_type": "code",
      "source": [
        "builder = StateGraph(ChatState)\n",
        "builder.add_node(\"add_message\", add_message)\n",
        "builder.add_edge(START, \"add_message\")\n",
        "builder.add_edge(\"add_message\", END)\n",
        "graph = builder.compile()"
      ],
      "metadata": {
        "id": "kdxhrU3N5xuB"
      },
      "id": "kdxhrU3N5xuB",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, create an input with a message and invoke the graph with this input:"
      ],
      "metadata": {
        "id": "6dKN_f176vRm"
      },
      "id": "6dKN_f176vRm"
    },
    {
      "cell_type": "code",
      "source": [
        "initial_state = ChatState(\n",
        "    messages = [HumanMessage(content=\"Hi\")], context=\"Customer support chat\"\n",
        ")\n",
        "\n",
        "result = graph.invoke(initial_state)\n",
        "print(f\"Output: {result}\")"
      ],
      "metadata": {
        "id": "K-UENULL646s",
        "outputId": "4f1e176c-73c7-453f-de44-4e8c2c2c7bcd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "K-UENULL646s",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output: {'messages': [HumanMessage(content='Hi', additional_kwargs={}, response_metadata={}), AIMessage(content='Hello there!', additional_kwargs={}, response_metadata={})], 'context': 'Customer support chat'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, convert back the result to Pydantic model to see the message types"
      ],
      "metadata": {
        "id": "PADTfLVz_uGM"
      },
      "id": "PADTfLVz_uGM"
    },
    {
      "cell_type": "code",
      "source": [
        "output_model = ChatState(**result)\n",
        "for i, msg in enumerate(output_model.messages):\n",
        "    print(f'Message {i}: {type(msg).__name__} - {msg.content}')"
      ],
      "metadata": {
        "id": "B5EKfztW_0ka",
        "outputId": "7d3c81d3-ce67-41f0-d054-3a2d860acba6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "B5EKfztW_0ka",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Message 0: HumanMessage - Hi\n",
            "Message 1: AIMessage - Hello there!\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}