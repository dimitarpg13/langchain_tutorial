{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "173ca196-34d9-43a5-9b86-f29f462e8c76",
      "metadata": {
        "id": "173ca196-34d9-43a5-9b86-f29f462e8c76"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/dimitarpg13/langchain_tutorial/blob/main/langchain_tutorial/notebooks/summarization/SimpleExample.ipynb)\n",
        "\n",
        "\n",
        "### Use Case\n",
        "\n",
        "Suppose you have a set of documents (PDFs, Notion pages, customer questions, etc) and you want to summarize the content.\n",
        "A central question for building a summarizer is how to pass your documents into the LLM's context window. Two common approaches for this are:\n",
        "\n",
        "1. `Stuff`: simply _stuff_ all your documents into a single promnpt. This is the simplest approach.\n",
        "2. `Map-reduce`: Summarize each document on its own in a _map_ step and then _reduce_ the summaries into a final summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "5f26900b-5c71-42af-b803-82ade0da1400",
      "metadata": {
        "id": "5f26900b-5c71-42af-b803-82ade0da1400"
      },
      "outputs": [],
      "source": [
        "%%capture --no-stderr\n",
        "%pip install --quiet -U langchain_openai langchain_core langchain_community tavily-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "eceb7822-59e0-44b9-a6ba-f4b5ee434fb6",
      "metadata": {
        "id": "eceb7822-59e0-44b9-a6ba-f4b5ee434fb6",
        "outputId": "3ff5396b-ca69-4414-aa62-8c4d9631a95e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "59cfbb9f-6da5-48b8-a974-7b792e3f7831",
      "metadata": {
        "id": "59cfbb9f-6da5-48b8-a974-7b792e3f7831",
        "outputId": "96f7cf0a-460a-4cd9-8570-ad95c38ebbd5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_community.utils.user_agent:USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "\n",
        "loader = WebBaseLoader(\"https://lilianweng.github.io/posts/2023-06-23-agent/\")\n",
        "docs = loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "05050ced-111c-4607-a551-0f3340dd7ad5",
      "metadata": {
        "id": "05050ced-111c-4607-a551-0f3340dd7ad5"
      },
      "outputs": [],
      "source": [
        "pip install -qU \"langchain[openai]\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "62f6e3ed-c728-4c35-b84f-e2673b0e0a7f",
      "metadata": {
        "id": "62f6e3ed-c728-4c35-b84f-e2673b0e0a7f"
      },
      "outputs": [],
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
        "  os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
        "\n",
        "from langchain.chat_models import init_chat_model\n",
        "\n",
        "llm = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e717d69-5f46-42f4-9eb1-56fc4d0c17c8",
      "metadata": {
        "id": "3e717d69-5f46-42f4-9eb1-56fc4d0c17c8"
      },
      "source": [
        "## Stuff: summarize in a single LLM call\n",
        "\n",
        "We can use [create_stuff_documents_chain](https://python.langchain.com/api_reference/langchain/chains/langchain.chains.combine_documents.stuff.create_stuff_documents_chain.html), especially if using models with larger context window (that is, at least hundred of kilobytes).\n",
        "\n",
        "Examples of models with large context windows:\n",
        "\n",
        "* 128K token OpenAI `gpt-4o`\n",
        "* 200K token Anthropic `claude-3-5-sonnet-20240620`\n",
        "\n",
        "The chain will take a list of documents, insert them all into a prompt , and pass that prompt to an LLM:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "a9b29c97-0191-4655-b388-4b0439ec80d6",
      "metadata": {
        "id": "a9b29c97-0191-4655-b388-4b0439ec80d6",
        "outputId": "7137a776-eadc-46dc-b757-c42d358c7546",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The article \"LLM Powered Autonomous Agents\" by Lilian Weng provides an in-depth exploration of autonomous agents that leverage large language models (LLMs) as their central controllers. It outlines a comprehensive system architecture for these agents, highlighting three main components: planning, memory, and tool usage.\n",
            "\n",
            "1. **Planning:** This component involves task decomposition into manageable subtasks and self-reflection, allowing agents to learn from past experiences and improve their decision-making processes. Various methodologies, such as Chain of Thought (CoT) and Tree of Thoughts, are discussed for enhancing planning capabilities.\n",
            "\n",
            "2. **Memory:** The article covers different types of memory, including sensory, short-term, and long-term memory, which help agents retain and recall information. Techniques for maximum inner product search (MIPS) are introduced to facilitate efficient information retrieval.\n",
            "\n",
            "3. **Tool Use:** The ability to interact with external tools significantly enhances agents' capabilities. The article discusses various frameworks, such as MRKL and HuggingGPT, which align LLMs with external tools to perform specific tasks, evidenced by case studies like ChemCrow for scientific discovery and Generative Agents for simulating human-like interactions.\n",
            "\n",
            "The article also identifies challenges in developing LLM-based agents, such as constrained context lengths, reliability of natural language interfaces, and the complexities of long-term planning, underscoring the need for ongoing research to overcome these barriers.\n",
            "\n",
            "In conclusion, Weng presents a vision for future developments in LLM-powered autonomous agents, indicating their potential as sophisticated problem solvers beyond simple text generation.\n"
          ]
        }
      ],
      "source": [
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain.chains.llm import LLMChain\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "# Define prompt\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [(\"system\", \"Write a concise summary of the following:\\\\n\\\\n{context}\")]\n",
        ")\n",
        "\n",
        "# Instantiate chain\n",
        "chain = create_stuff_documents_chain(llm, prompt)\n",
        "\n",
        "# Invoke chain\n",
        "result = chain.invoke({\"context\": docs})\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13cf0b29-0c21-4c51-8275-f885b39c39a8",
      "metadata": {
        "id": "13cf0b29-0c21-4c51-8275-f885b39c39a8"
      },
      "source": [
        "## Streaming\n",
        "Note that we can also stream the result token-by-token:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "24fdb384-b861-40fa-8c15-996b84797406",
      "metadata": {
        "id": "24fdb384-b861-40fa-8c15-996b84797406",
        "outputId": "495115a3-d871-40d6-9b95-162b3a7818ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|The| article| \"|LL|M| Powered| Autonomous| Agents|\"| by| Lil|ian| W|eng| discusses| the| potential| of| large| language| models| (|LL|Ms|)| as| the| core| controllers| of| autonomous| agents|.| It| presents| an| overview| of| an| L|LM|-powered| autonomous| agent| system|,| which| includes| three| main| components|:| Planning|,| Memory|,| and| Tool| Use|.| \n",
            "\n",
            "|1|.| **|Planning|**|:| This| involves| task| decomposition| into| manageable| sub|go|als| and| self|-ref|lection| to| improve| the| agent|'s| actions| based| on| past| experiences|.| Techniques| such| as| Chain| of| Thought| (|Co|T|)| and| Tree| of| Thoughts| (|To|T|)| are| highlighted| for| planning| complex| tasks|.\n",
            "\n",
            "|2|.| **|Memory|**|:| The| system| utilizes| various| memory| types| —| including| short|-term| and| long|-term| memory| —| enabling| agents| to| retain| significant| information|.| Maximum| Inner| Product| Search| (|M|IPS|)| algorithms| are| employed| for| efficient| information| retrieval| from| memory|.\n",
            "\n",
            "|3|.| **|Tool| Use|**|:| L|LM|s| are| equipped| with| the| ability| to| interact| with| external| APIs| and| tools|,| potentially| extending| their| functionalities|.| Examples| of| existing| L|LM|-powered| tools| illustrate| how| these| capabilities| can| facilitate| tasks| from| scientific| discovery| to| simple| user| interactions|.\n",
            "\n",
            "|Challenges| facing| L|LM|-powered| agents| are| also| discussed|,| including| their| limited| context| length|,| difficulties| in| long|-term| planning| and| task| decomposition|,| and| reliability| issues| with| natural| language| interfaces|.\n",
            "\n",
            "|The| article| provides| a| comprehensive| look| at| the| potential| and| challenges| of| building| autonomous| agents| using| L|LM|s|,| alongside| several| case| studies| and| proof|-of|-con|cept| examples|.||"
          ]
        }
      ],
      "source": [
        "for token in chain.stream({\"context\": docs}):\n",
        "    print(token, end=\"|\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a000b47-e1ea-453f-b314-003c168f9078",
      "metadata": {
        "id": "1a000b47-e1ea-453f-b314-003c168f9078"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
